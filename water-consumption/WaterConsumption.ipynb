{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cloudbutton Geospatial: Water Consumption Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T09:25:24.015057Z",
     "start_time": "2021-04-07T09:25:24.010199Z"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from cloudbutton_geospatial.io_utils.plot import plot_results\n",
    "from cloudbutton_geospatial.utils.notebook import date_picker\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from shapely.geometry import Point, MultiPoint, box\n",
    "from pprint import pprint\n",
    "import functools\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lithops\n",
    "import requests\n",
    "import rasterio\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import tempfile\n",
    "import concurrent.futures\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from lithops.storage import Storage\n",
    "from lithops.storage.utils import StorageNoSuchKeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area outside the processed tile that we want to consider for taking SIAM stations into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:28.795793Z",
     "start_time": "2021-04-13T14:38:28.788173Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "AREA_OF_INFLUENCE = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lithops Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:29.658886Z",
     "start_time": "2021-04-13T14:38:29.654251Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "DATA_BUCKET = 'cloudbutton-geospatial-wc'\n",
    "COMPUTE_BACKEND = 'aws_lambda'\n",
    "STORAGE_BACKEND = 'aws_s3'\n",
    "STORAGE_PREFIX = 's3://'\n",
    "RUNTIME = 'wc:03'\n",
    "RUNTIME_MEMORY = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "DTM_PREFIX = 'DTMs/'\n",
    "DTM_ASC_PREFIX = 'DTMs/asc/'\n",
    "DTM_GEOTIFF_PREFIX = 'DTMs/geotiff/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split tile into square chunks (number of tiles = SPLITS^2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:30.525082Z",
     "start_time": "2021-04-13T14:38:30.519883Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "SPLITS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation coefficient between elevation and temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:31.362634Z",
     "start_time": "2021-04-13T14:38:31.359578Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "r = -0.0056"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elevation to interpolate temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:32.187402Z",
     "start_time": "2021-04-13T14:38:32.184798Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "zdet = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day of year to calculate solar irradiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.IPythonDisplayFormatter object at 0x7fb56fcbdf10>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">, <Parameter \"include=None\">, <Parameter \"exclude=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.MimeBundleFormatter object at 0x7fb598083310>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&&&&& param include=None\n",
      "&&&&&&&&&&&&&&&&&&&&&& param.kind POSITIONAL_OR_KEYWORD\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.HTMLFormatter object at 0x7fb5a8068520>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.MarkdownFormatter object at 0x7fb5997f8700>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.SVGFormatter object at 0x7fb5a8060670>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PNGFormatter object at 0x7fb5997f8160>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PDFFormatter object at 0x7fb5a80607f0>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JPEGFormatter object at 0x7fb5a80607c0>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.LatexFormatter object at 0x7fb5a8060a00>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JSONFormatter object at 0x7fb5a8058880>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JavascriptFormatter object at 0x7fb5a8058cd0>, DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf36cf1fde1647a4a800d0e5d2ef554d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date', step=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date = date_picker(default=datetime.date(2022, 5, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:33.304420Z",
     "start_time": "2021-04-13T14:38:33.299098Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.IPythonDisplayFormatter object at 0x7fb56fcbdf10>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">, <Parameter \"include=None\">, <Parameter \"exclude=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.MimeBundleFormatter object at 0x7fb598083310>, 135)\n",
      "&&&&&&&&&&&&&&&&&&&&&& param include=None\n",
      "&&&&&&&&&&&&&&&&&&&&&& param.kind POSITIONAL_OR_KEYWORD\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PlainTextFormatter object at 0x7fb5a8058e50>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.HTMLFormatter object at 0x7fb5a8068520>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.MarkdownFormatter object at 0x7fb5997f8700>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.SVGFormatter object at 0x7fb5a8060670>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PNGFormatter object at 0x7fb5997f8160>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PDFFormatter object at 0x7fb5a80607f0>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JPEGFormatter object at 0x7fb5a80607c0>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.LatexFormatter object at 0x7fb5a8060a00>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JSONFormatter object at 0x7fb5a8058880>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JavascriptFormatter object at 0x7fb5a8058cd0>, 135)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAY_OF_YEAR = date.value.timetuple().tm_yday\n",
    "DAY_OF_YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Lithops Storage and Function Executor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:34.978991Z",
     "start_time": "2021-04-13T14:38:34.905888Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "storage = lithops.storage.Storage(backend=STORAGE_BACKEND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 00:20:28,815 [INFO] config.py:141 -- Lithops v2.9.1.dev0 - Python3.8\n",
      "2023-09-12 00:20:28,828 [INFO] aws_s3.py:68 -- S3 client created - Region: us-west-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 00:20:30,918 [INFO] aws_lambda.py:94 -- AWS Lambda client created - Region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "fexec = lithops.FunctionExecutor(backend=COMPUTE_BACKEND, storage=STORAGE_BACKEND, runtime=RUNTIME, runtime_memory=RUNTIME_MEMORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIAM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T09:46:49.948481Z",
     "start_time": "2021-04-07T09:46:49.800147Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n",
      "SIAM meteo data already in storage: {'x-amz-id-2': 'XxAKVGIv6IRjb9PF6TdFL63mMzd2AH41tTlxoWv3XO70DeCQlhT+mSOPrLNqatWLtcmPeQBRfu8=', 'x-amz-request-id': 'D8VY2B3VYC282H28', 'date': 'Tue, 12 Sep 2023 07:20:51 GMT', 'last-modified': 'Tue, 12 Sep 2023 03:34:51 GMT', 'etag': '\"8a1fd5da76b1123e66cc0155e6c8f5f7\"', 'x-amz-server-side-encryption': 'AES256', 'accept-ranges': 'bytes', 'content-type': 'binary/octet-stream', 'server': 'AmazonS3', 'content-length': '3850'}\n"
     ]
    }
   ],
   "source": [
    "siam_data_key = 'siam_data.csv'\n",
    "try:\n",
    "    siam_data_head = storage.head_object(bucket=DATA_BUCKET, key=siam_data_key)\n",
    "    print(f'SIAM meteo data already in storage: {siam_data_head}')\n",
    "except StorageNoSuchKeyError:\n",
    "    print('Uploading SIAM meteo data to Object Storage...')\n",
    "    with open(siam_data_key, 'rb') as f:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=siam_data_key, body=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n",
      "Shapefile already in storage: {'x-amz-id-2': 'XxAKVGIv6IRjb9PF6TdFL63mMzd2AH41tTlxoWv3XO70DeCQlhT+mSOPrLNqatWLtcmPeQBRfu8=', 'x-amz-request-id': 'D8VY2B3VYC282H28', 'date': 'Tue, 12 Sep 2023 07:20:51 GMT', 'last-modified': 'Tue, 12 Sep 2023 03:34:51 GMT', 'etag': '\"8a1fd5da76b1123e66cc0155e6c8f5f7\"', 'x-amz-server-side-encryption': 'AES256', 'accept-ranges': 'bytes', 'content-type': 'binary/octet-stream', 'server': 'AmazonS3', 'content-length': '3850'}\n"
     ]
    }
   ],
   "source": [
    "shapefile_key = 'shapefile_murcia.zip'\n",
    "try:\n",
    "    shapefile_head = storage.head_object(bucket=DATA_BUCKET, key=shapefile_key)\n",
    "    print(f'Shapefile already in storage: {siam_data_head}')\n",
    "except StorageNoSuchKeyError:\n",
    "    print('Uploading shapefile to Object Storage...')\n",
    "    with open(shapefile_key, 'rb') as f:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=shapefile_key, body=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital Terrain Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download DTM files for free from http://centrodedescargas.cnig.es/CentroDescargas/buscadorCatalogo.do?codFamilia=MDT05# and put them in `input_DTMs` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.IPythonDisplayFormatter object at 0x7fb56fcbdf10>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">, <Parameter \"include=None\">, <Parameter \"exclude=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.MimeBundleFormatter object at 0x7fb598083310>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&&&&& param include=None\n",
      "&&&&&&&&&&&&&&&&&&&&&& param.kind POSITIONAL_OR_KEYWORD\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PlainTextFormatter object at 0x7fb5a8058e50>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.HTMLFormatter object at 0x7fb5a8068520>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.MarkdownFormatter object at 0x7fb5997f8700>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.SVGFormatter object at 0x7fb5a8060670>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PNGFormatter object at 0x7fb5997f8160>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PDFFormatter object at 0x7fb5a80607f0>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JPEGFormatter object at 0x7fb5a80607c0>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.LatexFormatter object at 0x7fb5a8060a00>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JSONFormatter object at 0x7fb5a8058880>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JavascriptFormatter object at 0x7fb5a8058cd0>, ['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_asc_keys = storage.list_keys(bucket=DATA_BUCKET, prefix=DTM_ASC_PREFIX)\n",
    "dtm_asc_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find downloaded MDTs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T09:48:12.000399Z",
     "start_time": "2021-04-07T09:48:11.986192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%% ['.gitkeep', 'PNOA_MDT05_ETRS89_HU30_0818_LID.tif', 'PNOA_MDT05_ETRS89_HU30_0818_LID.asc']\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n",
      "***** ['input_DTMs/PNOA_MDT05_ETRS89_HU30_0818_LID.asc']\n",
      "Tile DTMs/asc/PNOA_MDT05_ETRS89_HU30_0818_LID.asc already in storage\n"
     ]
    }
   ],
   "source": [
    "local_dtm_input = 'input_DTMs'\n",
    "print(\"%%%%%%%%%%%%\",os.listdir(local_dtm_input))\n",
    "local_dtms = [os.path.join(local_dtm_input, dtm) for dtm in os.listdir(local_dtm_input) if dtm.endswith('.asc')]\n",
    "print(\"*****\", local_dtms)\n",
    "def upload_file(file_path):\n",
    "    key = os.path.join(DTM_ASC_PREFIX, os.path.basename(file_path))\n",
    "    if key in dtm_asc_keys:\n",
    "        print(f'Tile {key} already in storage')\n",
    "        return key\n",
    "    with open(file_path, 'rb') as f:\n",
    "        print(f'Uploading {key}...')\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=key, body=f)\n",
    "    return key\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as pool:\n",
    "    result = list(pool.map(upload_file, local_dtms))\n",
    "    # list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert ASCII raster files to Cloud Optimized GeoTIFF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://cloudbutton-geospatial-wc/DTMs/asc/\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(STORAGE_PREFIX, DATA_BUCKET, DTM_ASC_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n"
     ]
    }
   ],
   "source": [
    "def asc_to_geotiff(obj, storage):\n",
    "    print(\"$$$$$$$$$$$$$$$ obj\", obj)\n",
    "    print(\"$$$$$$$$$$$$$$$ obj.key\", obj.key)\n",
    "    print(\"$$$$$$$$$$$$$$$ obj.data_stream\", obj.data_stream)\n",
    "    asc_file_name = os.path.basename(obj.key)\n",
    "    tile_id, _ = os.path.splitext(asc_file_name)\n",
    "    out_path = os.path.join(tempfile.gettempdir(), tile_id + '.tiff')\n",
    "    out_key = os.path.join(DTM_GEOTIFF_PREFIX, tile_id + '.tiff')\n",
    "    \n",
    "    try:\n",
    "        out_obj = storage.head_object(bucket=DATA_BUCKET, key=out_key)\n",
    "    except StorageNoSuchKeyError:\n",
    "        out_obj = None\n",
    "    \n",
    "    if out_obj:\n",
    "        print(f'GeoTIFF {tile_id} already exists, skipping...')\n",
    "        return out_key\n",
    "    \n",
    "    print(f'Converting {tile_id} to GeoTIFF...')\n",
    "    with rasterio.open(obj.data_stream, 'r') as src:\n",
    "        profile = src.profile\n",
    "        # Cloud optimized GeoTiff parameters\n",
    "        profile.update(driver='GTiff')\n",
    "        profile.update(blockxsize=256)\n",
    "        profile.update(blockysize=256)\n",
    "        profile.update(tiled=True)\n",
    "        profile.update(compress='deflate')\n",
    "        profile.update(interleave='band')\n",
    "        with rasterio.open(out_path, 'w', **profile) as dest:\n",
    "            dest.write(src.read())\n",
    "    \n",
    "    with open(out_path, 'rb') as f:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=out_key, body=f)\n",
    "    \n",
    "    return out_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 00:49:19,790 [INFO] invokers.py:108 -- ExecutorID eece82-0 | JobID M001 - Selected Runtime: wc:03 - 2048MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n",
      "*******************iterdata s3://cloudbutton-geospatial-wc/DTMs/asc/\n",
      "*******************extra_args None\n",
      "*******************data ['s3://cloudbutton-geospatial-wc/DTMs/asc/']\n",
      "*******************func <function asc_to_geotiff at 0x7fb56b2dedc0>\n",
      "*******************new_parameters [<Parameter \"obj\">]\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args ('s3://cloudbutton-geospatial-wc/DTMs/asc/',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 00:49:21,923 [INFO] invokers.py:172 -- ExecutorID eece82-0 | JobID M001 - Starting function invocation: asc_to_geotiff() - Total: 1 activations\n",
      "2023-09-12 00:49:21,930 [INFO] invokers.py:208 -- ExecutorID eece82-0 | JobID M001 - View execution logs at /tmp/lithops-lithops/logs/eece82-0-M001.log\n"
     ]
    }
   ],
   "source": [
    "fs_cog = fexec.map(asc_to_geotiff, os.path.join(STORAGE_PREFIX, DATA_BUCKET, DTM_ASC_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 00:50:13,050 [INFO] wait.py:98 -- ExecutorID eece82-0 - Waiting for 100% of 1 function activations to complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"conn=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.history.HistoryManager object at 0x7fb5aa8a7c70>, <sqlite3.Connection object at 0x7fb5aaa8d8a0>)\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.IPythonDisplayFormatter object at 0x7fb56fcbdf10>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">, <Parameter \"include=None\">, <Parameter \"exclude=None\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.MimeBundleFormatter object at 0x7fb598083310>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&&&&& param include=None\n",
      "&&&&&&&&&&&&&&&&&&&&&& param.kind POSITIONAL_OR_KEYWORD\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.HTMLFormatter object at 0x7fb5a8068520>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.MarkdownFormatter object at 0x7fb5997f8700>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.SVGFormatter object at 0x7fb5a8060670>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PNGFormatter object at 0x7fb5997f8160>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.PDFFormatter object at 0x7fb5a80607f0>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JPEGFormatter object at 0x7fb5a80607c0>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.LatexFormatter object at 0x7fb5a8060a00>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JSONFormatter object at 0x7fb5a8058880>,     0%|          | 0/1  )\n",
      "&&&&&&&&&&&&&&&&&&& self.parameters.values() odict_values([<Parameter \"self\">, <Parameter \"obj\">])\n",
      "&&&&&&&&&&&&&&&&&&& args (<IPython.core.formatters.JavascriptFormatter object at 0x7fb5a8058cd0>,     0%|          | 0/1  )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd71b02fed449a3a8fdac4ea8b3fe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 00:50:13,065 [INFO] executors.py:593 -- ExecutorID eece82-0 - Cleaning temporary data\n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": "Read or write failed. /vsimem/985511eb-add8-4eec-83aa-eda8d39eb8d8/985511eb-add8-4eec-83aa-eda8d39eb8d8.tif, band 1: IReadBlock failed at X offset 0, Y offset 2074: /vsimem/985511eb-add8-4eec-83aa-eda8d39eb8d8/985511eb-add8-4eec-83aa-eda8d39eb8d8.tif, band 1: File short, can't read line 2074.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mfexec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs_cog\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/site-packages/lithops/executors.py:448\u001b[0m, in \u001b[0;36mFunctionExecutor.wait\u001b[0;34m(self, fs, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec, show_progressbar)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_handler\u001b[38;5;241m.\u001b[39mclear(present_jobs)\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean(clean_cloudobjects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_results:\n\u001b[1;32m    451\u001b[0m     fs_done \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone]\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/site-packages/lithops/executors.py:423\u001b[0m, in \u001b[0;36mFunctionExecutor.wait\u001b[0;34m(self, fs, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec, show_progressbar)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# Start waiting for results\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 423\u001b[0m     \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m         \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m         \u001b[49m\u001b[43mjob_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdownload_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m         \u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m         \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_when\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m         \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m         \u001b[49m\u001b[43mthreadpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreadpool_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m         \u001b[49m\u001b[43mwait_dur_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_dur_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m         \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_cleaner \u001b[38;5;129;01mand\u001b[39;00m return_when \u001b[38;5;241m==\u001b[39m ALL_COMPLETED:\n\u001b[1;32m    435\u001b[0m         present_jobs \u001b[38;5;241m=\u001b[39m {f\u001b[38;5;241m.\u001b[39mjob_key \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures}\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/site-packages/lithops/wait.py:160\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, internal_storage, job_monitor, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec, show_progressbar)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_unix_system():\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/site-packages/lithops/wait.py:141\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, internal_storage, job_monitor, throw_except, return_when, download_results, timeout, threadpool_size, wait_dur_sec, show_progressbar)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _check_done(fs, return_when, download_results):\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m executor_data \u001b[38;5;129;01min\u001b[39;00m executors_data:\n\u001b[0;32m--> 141\u001b[0m                 new_data \u001b[38;5;241m=\u001b[39m \u001b[43m_get_executor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mdownload_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mthreadpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreadpool_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_data \u001b[38;5;28;01melse\u001b[39;00m sleep_sec)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/site-packages/lithops/wait.py:287\u001b[0m, in \u001b[0;36m_get_executor_data\u001b[0;34m(fs, exec_data, download_results, throw_except, threadpool_size, pbar)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mlist\u001b[39m(pool\u001b[38;5;241m.\u001b[39mmap(get_result, fs_to_wait_on))\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_status\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs_to_wait_on\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m pool\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/concurrent/futures/_base.py:611\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/concurrent/futures/_base.py:388\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m--> 388\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/concurrent/futures/thread.py:57\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/site-packages/lithops/wait.py:281\u001b[0m, in \u001b[0;36m_get_executor_data.<locals>.get_status\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_status\u001b[39m(f):\n\u001b[0;32m--> 281\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthrow_except\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrow_except\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexec_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_storage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/site-packages/lithops/future.py:255\u001b[0m, in \u001b[0;36mResponseFuture.status\u001b[0;34m(self, throw_except, internal_storage, check_only)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m throw_except:\n\u001b[1;32m    254\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexcepthook \u001b[38;5;241m=\u001b[39m exception_hook\n\u001b[0;32m--> 255\u001b[0m     \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(msg1)\n",
      "File \u001b[0;32m~/miniconda3/envs/python3.8/lib/python3.8/site-packages/six.py:718\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    716\u001b[0m         value \u001b[38;5;241m=\u001b[39m tp()\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/lithops/lithops/worker/jobrunner.py:236\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m, in \u001b[0;36masc_to_geotiff\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     profile\u001b[38;5;241m.\u001b[39mupdate(interleave\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mband\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(out_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprofile) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[0;32m---> 30\u001b[0m         dest\u001b[38;5;241m.\u001b[39mwrite(src\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     33\u001b[0m     storage\u001b[38;5;241m.\u001b[39mput_object(bucket\u001b[38;5;241m=\u001b[39mDATA_BUCKET, key\u001b[38;5;241m=\u001b[39mout_key, body\u001b[38;5;241m=\u001b[39mf)\n",
      "File \u001b[0;32mrasterio/_io.pyx:367\u001b[0m, in \u001b[0;36mrasterio._io.DatasetReaderBase.read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_io.pyx:704\u001b[0m, in \u001b[0;36mrasterio._io.DatasetReaderBase._read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: Read or write failed. /vsimem/985511eb-add8-4eec-83aa-eda8d39eb8d8/985511eb-add8-4eec-83aa-eda8d39eb8d8.tif, band 1: IReadBlock failed at X offset 0, Y offset 2074: /vsimem/985511eb-add8-4eec-83aa-eda8d39eb8d8/985511eb-add8-4eec-83aa-eda8d39eb8d8.tif, band 1: File short, can't read line 2074."
     ]
    }
   ],
   "source": [
    "_, _ = fexec.wait(fs=fs_cog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_geotiff_keys = storage.list_keys(bucket=DATA_BUCKET, prefix=DTM_GEOTIFF_PREFIX)\n",
    "# dtm_geotiff_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get bounds and tile ID for every tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_meta(obj):\n",
    "    tile_id = os.path.splitext(os.path.basename(obj.key))[0]\n",
    "    with rasterio.open(obj.data_stream, 'r') as src:\n",
    "        x1, y1 = src.profile['transform'] * (0, 0)\n",
    "        x2, y2 = src.profile['transform'] * (src.profile['width'], src.profile['height'])\n",
    "    return tile_id, (x1, y1), (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_meta = fexec.map(get_tile_meta, os.path.join(STORAGE_PREFIX, DATA_BUCKET, DTM_GEOTIFF_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_meta = fexec.get_result(fs=fs_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "import ipywidgets\n",
    "import utm\n",
    "\n",
    "m = ipyleaflet.Map(center=(38.082906, -1.330466), zoom=9.5)\n",
    "\n",
    "for tile_id, bound1, bound2 in tiles_meta:\n",
    "    x1, y1 = bound1\n",
    "    x2, y2 = bound2\n",
    "    xc, yc = (x1 + x2) / 2, y1\n",
    "    \n",
    "    wgs_bounds_1 = utm.to_latlon(x1, y1, 30, 'S')\n",
    "    wgs_bounds_2 = utm.to_latlon(x2, y2, 30, 'S')\n",
    "    # wgs_bounds_c = utm.to_latlon(xc, yc, 30, 'S')\n",
    "\n",
    "    rectangle = ipyleaflet.Rectangle(bounds=(wgs_bounds_1, wgs_bounds_2))\n",
    "    m.add_layer(rectangle)    \n",
    "\n",
    "m.layout.height=\"750px\"\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster Data Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data tiles in subtiles for increased parallelism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_chunker(obj, n_splits, block_x, block_y, storage):\n",
    "    tile_key = os.path.basename(obj.key)\n",
    "    tile_id, _ = os.path.splitext(tile_key)\n",
    "    \n",
    "    with rasterio.open(obj.data_stream) as src:\n",
    "        transform = src.transform\n",
    "        \n",
    "        # Compute working window\n",
    "        step_w = src.width / n_splits\n",
    "        step_h = src.height / n_splits\n",
    "        \n",
    "        offset_h = round(step_h * block_x)\n",
    "        offset_w = round(step_w * block_y)\n",
    "        \n",
    "        profile = src.profile\n",
    "        \n",
    "        width = math.ceil(step_w * (block_y + 1) - offset_w)\n",
    "        height = math.ceil(step_h * (block_x + 1) - offset_h)\n",
    "        \n",
    "        profile.update(width=width)\n",
    "        profile.update(height=height)\n",
    "        \n",
    "        window = Window(offset_w, offset_h, width, height)\n",
    "        \n",
    "        chunk_file = os.path.join(tempfile.gettempdir(), tile_id + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "        with rasterio.open(chunk_file, 'w', **profile) as dest:\n",
    "            dest.write(src.read(window=window))\n",
    "    \n",
    "    with open(chunk_file, 'rb') as f:\n",
    "        co = storage.put_cloudobject(body=f, bucket=DATA_BUCKET)\n",
    "    \n",
    "    return (tile_key, block_x, block_y, co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterdata = [(os.path.join(STORAGE_PREFIX, DATA_BUCKET, tile), SPLITS, i, j)\n",
    "            for i in range(SPLITS) for j in range(SPLITS) for tile in dtm_geotiff_keys]\n",
    "print(f'Chunking {len(dtm_geotiff_keys)} tiles in {SPLITS * SPLITS} chunks each using {len(iterdata)} functions')\n",
    "# iterdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker_fs = fexec.map(data_chunker, iterdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = fexec.get_result(fs=chunker_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute solar irradiation for a given day of year using GRASS libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:54.462039Z",
     "start_time": "2021-04-13T14:38:54.449706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_solar_irradiation(inputFile, outputFile, crs='32630'):\n",
    "    # Define grass working set\n",
    "    GRASS_GISDB = 'grassdata'\n",
    "    GRASS_LOCATION = 'GEOPROCESSING'\n",
    "    GRASS_MAPSET = 'PERMANENT'\n",
    "    GRASS_ELEVATIONS_FILENAME = 'ELEVATIONS'\n",
    "\n",
    "    os.environ['GRASSBIN'] = 'grass76'\n",
    "    from grass_session import Session\n",
    "    import grass.script as gscript\n",
    "    from grass.pygrass.modules.shortcuts import general\n",
    "    from grass.pygrass.modules.shortcuts import raster\n",
    "\n",
    "    os.environ.update(dict(GRASS_COMPRESS_NULLS='1'))\n",
    "    \n",
    "    # Clean previously processed data\n",
    "    if os.path.isdir(GRASS_GISDB):\n",
    "        shutil.rmtree(GRASS_GISDB)\n",
    "    \n",
    "    with Session(gisdb=GRASS_GISDB, location=GRASS_LOCATION, mapset=GRASS_MAPSET, create_opts='EPSG:32630') as ses:\n",
    "        # Set project projection to match elevation raster projection\n",
    "        general.proj(epsg=crs, flags='c') \n",
    "    \n",
    "        # Load raster file into working directory\n",
    "        raster.import_(input=inputFile, output=GRASS_ELEVATIONS_FILENAME, flags='o')    \n",
    "        \n",
    "        # Set project region to match raster region\n",
    "        general.region(raster=GRASS_ELEVATIONS_FILENAME, flags='s')    \n",
    "        # Calculate solar irradiation\n",
    "        gscript.run_command('r.slope.aspect', elevation=GRASS_ELEVATIONS_FILENAME,\n",
    "                            slope='slope', aspect='aspect')\n",
    "        gscript.run_command('r.sun', elevation=GRASS_ELEVATIONS_FILENAME,\n",
    "                            slope='slope', aspect='aspect', beam_rad='beam',\n",
    "                            step=1, day=DAY_OF_YEAR)\n",
    "        \n",
    "        # Get extraterrestrial irradiation from history metadata\n",
    "        regex = re.compile(r'\\d+\\.\\d+')\n",
    "        output = gscript.read_command(\"r.info\", flags=\"h\", map=[\"beam\"])\n",
    "        splits = str(output).split('\\n')\n",
    "        line = next(filter(lambda line: 'Extraterrestrial' in line, splits))\n",
    "        extraterrestrial_irradiance = float(regex.search(line)[0])\n",
    "        \n",
    "        # Export generated results into a GeoTiff file\n",
    "        if os.path.isfile(outputFile):\n",
    "            os.remove(outputFile)\n",
    "\n",
    "        raster.out_gdal(input='beam', output=outputFile)\n",
    "        \n",
    "        return extraterrestrial_irradiance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get stations contained in the area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:55.461635Z",
     "start_time": "2021-04-13T14:38:55.457230Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_stations(bounds, stations):\n",
    "    total_points = MultiPoint([Point(x,y) for x, y in stations[['X', 'Y']].to_numpy()])\n",
    "    intersection = bounds.buffer(AREA_OF_INFLUENCE).intersection(total_points)\n",
    "    \n",
    "    return stations[[ intersection.contains(point) for point in total_points]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Distance Weighting interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:58.209269Z",
     "start_time": "2021-04-13T14:38:58.202597Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_basic_interpolation(shape, stations, field_value, offset = (0,0)):\n",
    "    station_pixels = [[pixel[0], pixel[1]] for pixel in stations['pixel'].to_numpy()]\n",
    "    \n",
    "    # Get an array where each position represents pixel coordinates\n",
    "    tile_pixels = np.indices(shape).transpose(1,2,0).reshape(shape[0]*shape[1], 2) + offset\n",
    "    dist = distance_matrix(station_pixels, tile_pixels)\n",
    "    weights = np.where(dist == 0, np.finfo('float32').max, 1.0 / dist )\n",
    "    weights /=  weights.sum(axis=0)\n",
    "    \n",
    "    return np.dot(weights.T, stations[field_value].to_numpy()).reshape(shape).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate temperatures from a subset of the tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:59.031150Z",
     "start_time": "2021-04-13T14:38:59.005158Z"
    }
   },
   "outputs": [],
   "source": [
    "def radiation_interpolation(tile_key, block_x, block_y, chunk_cloudobject, storage):\n",
    "    tile_id, _ = os.path.splitext(tile_key)\n",
    "    print(tile_id)\n",
    "    \n",
    "    # Write tile chunk to file\n",
    "    chunk_file = os.path.join(tempfile.gettempdir(), tile_id + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "    print(chunk_file)\n",
    "    with open(chunk_file, 'wb') as f:\n",
    "        body = storage.get_cloudobject(chunk_cloudobject)\n",
    "        f.write(body)\n",
    "    \n",
    "    with rasterio.open(chunk_file, 'r') as chunk_src:\n",
    "        profile = chunk_src.profile\n",
    "        \n",
    "    extr_chunk_file = os.path.join(tempfile.gettempdir(), tile_id + '_extr_' + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "    rad_chunk_file = os.path.join(tempfile.gettempdir(), tile_id + '_rad_' + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "    \n",
    "    # Compute solar irradiation from inputFile, creates radiation raster at outputFile\n",
    "    extraterrestrial_irradiation = compute_solar_irradiation(inputFile=chunk_file, outputFile=rad_chunk_file)\n",
    "        \n",
    "    # Create and store a raster with extraterrestrial irradiation\n",
    "    with rasterio.open(extr_chunk_file, 'w', **profile) as dest:\n",
    "        data = np.full((profile['height'], profile['width']), extraterrestrial_irradiation, dtype='float32')\n",
    "        dest.write(data, 1)\n",
    "    \n",
    "    with open(extr_chunk_file, 'rb') as f:\n",
    "        extr_co = storage.put_cloudobject(body=f, bucket=DATA_BUCKET)\n",
    "    \n",
    "    with open(rad_chunk_file, 'rb') as f:\n",
    "        rad_co = storage.put_cloudobject(body=f, bucket=DATA_BUCKET)\n",
    "    \n",
    "    return [(tile_key, 'extr', block_x, block_y, extr_co), (tile_key, 'rad', block_x, block_y, rad_co)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:39:01.538202Z",
     "start_time": "2021-04-13T14:39:01.521080Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_interpolation(tile_key, block_x, block_y, chunk_cloudobject, data_field, storage):\n",
    "    tile_id, _ = os.path.splitext(tile_key)\n",
    "    \n",
    "    # Get SIAM meteo data\n",
    "    siam_stream = storage.get_object(DATA_BUCKET, siam_data_key, stream=True)\n",
    "    siam_data = pd.read_csv(siam_stream)\n",
    "    \n",
    "    chunk = storage.get_cloudobject(chunk_cloudobject, stream=True)\n",
    "    \n",
    "    with rasterio.open(chunk) as chunk_src:\n",
    "        transform = chunk_src.transform\n",
    "        profile = chunk_src.profile\n",
    "        \n",
    "        bounding_rect = box(chunk_src.bounds.left, chunk_src.bounds.top, chunk_src.bounds.right, chunk_src.bounds.bottom)\n",
    "        filtered = pd.DataFrame(filter_stations(bounding_rect, siam_data))\n",
    "        \n",
    "        if filtered.shape[0] == 0:\n",
    "            return [(tile_key, data_field, block_x, block_y, None)]\n",
    "        \n",
    "        filtered['pixel'] = filtered.apply(lambda station: rasterio.transform.rowcol(transform, station['X'], station['Y']), axis=1)\n",
    "                \n",
    "        # Interpolate variables from meteo station data, generate raster with result\n",
    "        dest_chunk_file = os.path.join(tempfile.gettempdir(), tile_id + '_' + data_field + '_' + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "        \n",
    "        with rasterio.open(dest_chunk_file, 'w', **profile) as chunk_dest:\n",
    "            if data_field == 'temp':\n",
    "                elevations = chunk_src.read(1)  # Get elevations content\n",
    "                interpolation = compute_basic_interpolation(elevations.shape, filtered, 'tdet', (0, 0))\n",
    "                interpolation += r * (elevations - zdet)\n",
    "                chunk_dest.write(np.where(elevations == chunk_src.nodata, np.nan, interpolation), 1)\n",
    "            elif data_field == 'humi':\n",
    "                interpolation = compute_basic_interpolation((profile['height'], profile['width']), filtered, 'hr', (0, 0))\n",
    "                chunk_dest.write(interpolation, 1)\n",
    "            elif data_field == 'wind':\n",
    "                interpolation = compute_basic_interpolation((profile['height'], profile['width']), filtered, 'v', (0, 0))\n",
    "                chunk_dest.write(interpolation, 1)\n",
    "            else:\n",
    "                raise Exception(f'Unknown data field \"{data_field}\"')\n",
    "\n",
    "    # Upload results to storage as Cloudobject\n",
    "    with open(dest_chunk_file, 'rb') as f:\n",
    "        co = storage.put_cloudobject(body=f, bucket=DATA_BUCKET)\n",
    "    \n",
    "    return [(tile_key, data_field, block_x, block_y, co)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lithops serverless computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T06:56:29.270356Z",
     "start_time": "2021-04-08T06:56:27.066344Z"
    }
   },
   "outputs": [],
   "source": [
    "fs_rad = fexec.map(radiation_interpolation, chunks, runtime_memory=2048)\n",
    "fs_temp = fexec.map(map_interpolation, chunks, extra_args=('temp', ), runtime_memory=2048)\n",
    "fs_humi = fexec.map(map_interpolation, chunks, extra_args=('humi', ), runtime_memory=2048)\n",
    "fs_wind = fexec.map(map_interpolation, chunks, extra_args=('wind', ), runtime_memory=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rad = fexec.get_result(fs=fs_rad)\n",
    "res_temp = fexec.get_result(fs=fs_temp)\n",
    "res_humi = fexec.get_result(fs=fs_humi)\n",
    "res_wind = fexec.get_result(fs=fs_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_flatten = []\n",
    "for l in [res_rad, res_temp, res_humi, res_wind]:\n",
    "    for elem in l:\n",
    "        for sub_elem in elem:\n",
    "            res_flatten.append(sub_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_chunks = collections.defaultdict(list)\n",
    "\n",
    "for chunk_result in res_flatten:\n",
    "    tile_key, data_field, block_x, block_y, co = chunk_result\n",
    "    grouped_chunks[(tile_key, data_field)].append((block_x, block_y, co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join split subsets into a tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_blocks(tile_data, chunks, storage):\n",
    "    from rasterio.windows import Window\n",
    "    \n",
    "    tile_key, data_field = tile_data\n",
    "    \n",
    "    cobjs = [tup[2] for tup in chunks]\n",
    "    if None in cobjs:\n",
    "        return None\n",
    "    \n",
    "    # Get width and height from original tile\n",
    "    source_tile_key = os.path.join(DTM_GEOTIFF_PREFIX, tile_key)\n",
    "    with rasterio.open(storage.get_object(bucket=DATA_BUCKET, key=source_tile_key, stream=True)) as source_tile:\n",
    "        height = source_tile.profile['height']\n",
    "        width = source_tile.profile['width']\n",
    "        \n",
    "    # Open first object to obtain profile metadata\n",
    "    with rasterio.open(storage.get_cloudobject(chunks[0][2], stream=True)) as chunk_src:\n",
    "        profile = chunk_src.profile\n",
    "        profile.update(width=width)\n",
    "        profile.update(height=height)\n",
    "\n",
    "    # Iterate each object and print its block into the destination file\n",
    "    merged_file = os.path.join(tempfile.gettempdir(), data_field + '_' + tile_key)\n",
    "    with rasterio.open(merged_file, 'w', **profile) as dest: \n",
    "        for chunk in chunks:\n",
    "            j, i, co = chunk\n",
    "            with rasterio.open(storage.get_cloudobject(co, stream=True)) as src:\n",
    "                step_w = math.floor(width / SPLITS)\n",
    "                step_h = math.floor(height / SPLITS)\n",
    "                curr_window = Window(round(step_w * i), round(step_h * j), src.width, src.height)\n",
    "                content = src.read(1)\n",
    "                dest.write(content, 1, window=curr_window)\n",
    "    \n",
    "    output_key = os.path.join(DTM_PREFIX, data_field, tile_key)\n",
    "    with open(merged_file, 'rb') as out_file:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=output_key, body=out_file)  \n",
    "    \n",
    "    return output_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine previous split subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterdata = []\n",
    "for (tile_id, data_field), chunks in grouped_chunks.items():\n",
    "    iterdata.append(((tile_id, data_field), chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_merged = fexec.map(merge_blocks, iterdata, runtime_memory=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_merged = fexec.get_result(fs=fs_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_keys_merged = set([os.path.basename(t) for t in tiles_merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile_keys_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of potential evaporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:51.493674Z",
     "start_time": "2021-04-13T16:57:51.485032Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_crop_evapotranspiration(temperatures,\n",
    "                                    humidities,\n",
    "                                    wind_speeds,\n",
    "                                    external_radiations,\n",
    "                                    global_radiations,\n",
    "                                    KCs):\n",
    "    gamma = 0.665*101.3/1000\n",
    "    eSat = 0.6108 * np.exp((17.27*temperatures)/(temperatures+237.3))\n",
    "    delta = 4098 * eSat / np.power((temperatures + 237.3),2)\n",
    "    eA = np.where(humidities < 0, 0, eSat * humidities / 100)     # Avoid sqrt of a negative number\n",
    "    T4 = 4.903 * np.power((273.3 + temperatures),4)/1000000000\n",
    "    rSrS0 = global_radiations/(external_radiations * 0.75)\n",
    "    rN = 0.8* global_radiations-T4*(0.34-0.14*np.sqrt(eA))*((1.35*rSrS0)-0.35)\n",
    "    den = delta + gamma *(1 + 0.34* wind_speeds)\n",
    "    tRad = 0.408 * delta * rN / den\n",
    "    tAdv = gamma * (900/(temperatures+273))*wind_speeds * (eSat - eA)/den\n",
    "    return ((tRad + tAdv) * 7 * KCs).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:52.760441Z",
     "start_time": "2021-04-13T16:57:52.753812Z"
    }
   },
   "outputs": [],
   "source": [
    "vineyard = ['VI', 'VO', 'VF', 'FV', 'CV' ]\n",
    "olive_grove = ['OV', 'VO', 'OF', 'FL', 'OC']\n",
    "fruit = ['FY', 'VF', 'OF', 'FF', 'CF']\n",
    "nuts = ['FS', 'FV', 'FL', 'FF', 'CS' ]\n",
    "citrus = ['CI', 'CV', 'OC', 'CF', 'CS' ]\n",
    "\n",
    "def get_kc(feature):\n",
    "    # TODO: Get more precise values of Kc\n",
    "    print(feature['properties'].keys())\n",
    "    # sigpac_use = feature['properties']['uso_sigpac']\n",
    "    sigpac_use = 'FF'\n",
    "    if sigpac_use in vineyard:\n",
    "        # Grapes for wine - 0.3, 0.7, 0.45\n",
    "        return 0.7  \n",
    "    if sigpac_use in olive_grove:\n",
    "        # Olive grove - ini: 0.65, med: 0.7, end: 0.7\n",
    "        return 0.7 \n",
    "    if sigpac_use in fruit:\n",
    "        # Apples, Cherries, Pears - 0.45, 0.95, 0.7\n",
    "        return 0.95\n",
    "    if sigpac_use in nuts:\n",
    "        # Almonds - 0.4, 0.9, 0.65\n",
    "        return 0.9\n",
    "    if sigpac_use in citrus:\n",
    "        # Citrus, without ground coverage - 0.7, 0.65, 0.7\n",
    "        return 0.65\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:54.250115Z",
     "start_time": "2021-04-13T16:57:54.243932Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_geometry_window(src, geom_bounds):\n",
    "    left, bottom, right, top = geom_bounds\n",
    "    src_left, src_bottom, src_right, src_top = src.bounds\n",
    "    window = src.window(max(left,src_left), max(bottom,src_bottom), min(right,src_right), min(top,src_top))\n",
    "    window_floored = window.round_offsets(op='floor', pixel_precision=3)\n",
    "    w = math.ceil(window.width + window.col_off - window_floored.col_off)\n",
    "    h = math.ceil(window.height + window.row_off - window_floored.row_off)\n",
    "    return Window(window_floored.col_off, window_floored.row_off, w, h)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:57.781920Z",
     "start_time": "2021-04-13T16:57:57.770029Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_evapotranspiration_by_shape(tem, hum, win, rad, extrad, dst):\n",
    "    \n",
    "    import fiona\n",
    "    from shapely.geometry import shape, box\n",
    "    from rasterio import features\n",
    "    \n",
    "    non_arable_land = ['AG', 'CA', 'ED', 'FO', 'IM', 'PA', 'PR', 'ZU', 'ZV']\n",
    "    \n",
    "    with fiona.open('zip://shape.zip') as shape_src:\n",
    "        for feature in shape_src.filter(bbox=tem.bounds):\n",
    "            KC = get_kc(feature) \n",
    "            if KC is not None:   \n",
    "                geom = shape(feature['geometry'])  \n",
    "                window = get_geometry_window(tem, geom.bounds)              \n",
    "                win_transform = rasterio.windows.transform(window, tem.transform)\n",
    "                # Convert shape to raster matrix\n",
    "                image = features.rasterize([geom],\n",
    "                                           out_shape=(window.height, window.width),\n",
    "                                           transform = win_transform,\n",
    "                                           fill = 0,\n",
    "                                           default_value = 1).astype('bool')\n",
    "                # Get values to compute evapotranspiration\n",
    "                temperatures = tem.read(1, window=window)\n",
    "                humidities = hum.read(1, window=window)\n",
    "                wind_speeds = win.read(1, window=window)\n",
    "                # Convert from W to MJ (0.0036)\n",
    "                global_radiations = rad.read(1, window=window) * 0.0036\n",
    "                external_radiations = extrad.read(1, window=window) * 0.0036\n",
    "                KCs = np.full(temperatures.shape, KC)\n",
    "                # TODO: compute external radiation\n",
    "                #external_radiations = np.full(temperatures.shape, 14)\n",
    "                # TODO: compute global radiation\n",
    "                # global_radiations = np.full(temperatures.shape, 10)\n",
    "                etc = compute_crop_evapotranspiration(\n",
    "                        temperatures,\n",
    "                        humidities,\n",
    "                        wind_speeds,\n",
    "                        external_radiations,\n",
    "                        global_radiations,\n",
    "                        KCs\n",
    "                )\n",
    "                etc[temperatures == tem.nodata] = dst.nodata\n",
    "                etc[np.logical_not(image)] = dst.nodata\n",
    "                dst.write(etc + dst.read(1, window=window), 1, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:59.216824Z",
     "start_time": "2021-04-13T16:57:59.207435Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_global_evapotranspiration(tem, hum, win, rad, extrad, dst):    \n",
    "    for ji, window in tem.block_windows(1):\n",
    "        bounds = rasterio.windows.bounds(window, tem.transform)\n",
    "        temperatures = tem.read(1, window=window)\n",
    "        humidities = hum.read(1, window=window)\n",
    "        wind_speeds = win.read(1, window=window)\n",
    "         # Convert from W to MJ (0.0036)\n",
    "        global_radiations = rad.read(1, window=window) * 0.0036\n",
    "        external_radiations = extrad.read(1, window=window) * 0.0036\n",
    "        # TODO: compute external radiation\n",
    "        #external_radiations = np.full(temperatures.shape, 14)\n",
    "        # TODO: compute global radiation\n",
    "        # global_radiations = np.full(temperatures.shape, 10)\n",
    "        # TODO: compute KCs\n",
    "        KCs = np.full(temperatures.shape, 1)\n",
    "        etc = compute_crop_evapotranspiration(\n",
    "                temperatures,\n",
    "                humidities,\n",
    "                wind_speeds,\n",
    "                external_radiations,\n",
    "                global_radiations,\n",
    "                KCs\n",
    "        )\n",
    "        dst.write(np.where(temperatures == tem.nodata, dst.nodata, etc), 1, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:58:01.128416Z",
     "start_time": "2021-04-13T16:58:01.101842Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_calculations(tile_key, storage):\n",
    "    \n",
    "    from functools import partial\n",
    "      \n",
    "    # Download shapefile\n",
    "    shapefile = storage.get_object(bucket=DATA_BUCKET, key='shapefile_murcia.zip', stream=True)\n",
    "    with open('shape.zip', 'wb') as shapf:\n",
    "        for chunk in iter(partial(shapefile.read, 200 * 1024 * 1024), ''):\n",
    "            if not chunk:\n",
    "                break\n",
    "            shapf.write(chunk)\n",
    "    try:\n",
    "        temp = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'temp', tile_key), stream=True)\n",
    "        humi = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'humi', tile_key), stream=True)\n",
    "        rad = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'rad', tile_key), stream=True)\n",
    "        extrad = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'extr', tile_key), stream=True)\n",
    "        wind = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'wind', tile_key), stream=True)\n",
    "    except StorageNoSuchKeyError:\n",
    "        return None\n",
    "    \n",
    "    output_file = os.path.join(tempfile.gettempdir(), 'eva' + '_' + tile_key)\n",
    "    with rasterio.open(temp) as temp_raster:\n",
    "        with rasterio.open(humi) as humi_raster:\n",
    "            with rasterio.open(rad) as rad_raster:\n",
    "                with rasterio.open(extrad) as extrad_raster:\n",
    "                    with rasterio.open(wind) as wind_raster:\n",
    "                        profile = temp_raster.profile\n",
    "                        profile.update(nodata=0)\n",
    "                        with rasterio.open(output_file, 'w+', **profile) as dst:\n",
    "#                             compute_global_evapotranspiration(temp_raster, humi_raster, wind_raster,\n",
    "#                                                               rad_raster, extrad_raster, dst)\n",
    "                            compute_evapotranspiration_by_shape(temp_raster, humi_raster, wind_raster,\n",
    "                                                                rad_raster, extrad_raster, dst)\n",
    "    \n",
    "    output_key = os.path.join(DTM_PREFIX, 'eva', tile_key)\n",
    "    with open(output_file, 'rb') as output_f:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=output_key, body=output_f)\n",
    "    return output_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:58:55.822484Z",
     "start_time": "2021-04-13T16:58:54.943303Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs_eva = fexec.map(combine_calculations, tile_keys_merged, runtime_memory=2048)\n",
    "res_eva = fexec.get_result(fs=fs_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_eva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec.plot(dst=fexec.executor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec.clean(clean_cloudobjects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec.job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dtm_asc_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sz = 0\n",
    "for input_key in dtm_asc_keys:\n",
    "    meta = storage.head_object(bucket=DATA_BUCKET, key=input_key)\n",
    "    input_sz += int(meta['content-length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_key = os.path.basename(tile)\n",
    "tile_id, _ = os.path.splitext(tile_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T21:32:01.429761Z",
     "start_time": "2021-04-13T21:32:00.245568Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "with rasterio.open('PNOA_MDT05_ETRS89_HU30_0891_LID.tiff') as src:\n",
    "    arr = src.read(1, out_shape=(src.height, src.width))\n",
    "    ax.set_title(tile_id)\n",
    "    img = ax.imshow(arr, cmap='Greens')\n",
    "    fig.colorbar(img, shrink=0.5)\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "# obj.seek(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
